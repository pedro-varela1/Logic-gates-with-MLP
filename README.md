# Logic-gates-with-MLP
Artificial Neural Network project with Multi-Layer Perceptron Algorithm to learn logic gates in C++.

  The following code presents a class named "Perceptron" that performs forward propagation and trains an artificial neural network to behave like a logic gate.
  The activation function of the artificial neural network is the sigmoid, in order to keep the outputs in the interval between 0 and 1. Therefore, the algorithm is not limited only to logic gates.
  The training is carried out based on the Backpropagation algorithm and the values of the total iterations and acceptable sum of squares of the error are previously defined: 10,000 and 0.01 respectively.
  Values such as number of hidden neurons, number of inputs, number of outputs and training data are previously defined and are subject to change. Furthermore, the neural network weights are randomly defined.
  Finally, it is noticeable that the code is a study model for the operation of an artificial neural network, since there is no practical application.
